{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /gpfs/space/home/danylobo/bm-ai-pipelines/common/ocs/lightning_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchmetrics\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "from inference_utils import predict_frame, get_model, draw_contours_from_mask, filter_axes, imshow\n",
    "from pathlib import Path\n",
    "from dataset.dataset import OneclickDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.show()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 2\n",
    "\n",
    "version = 30\n",
    "ckpt_dir = Path(f\"lightning_logs/2D-segm/version_{version}/checkpoints\")\n",
    "ckpt_path = list(ckpt_dir.iterdir())[0]\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val set:\n",
    "img_dir = Path(\"/gpfs/space/projects/BetterMedicine/danylo/lung/training/raw/2D-001_LIDC_thin_CropPad_consensus1/Ts/images\")\n",
    "# test set thick=2.5\n",
    "img_dir = Path(\"/gpfs/space/projects/BetterMedicine/danylo/lung/training/raw/2D-001_LIDC_thick=2_5_CropPad_consensus1-Tr/images\")\n",
    "# test 201 redbrick\n",
    "img_dir = Path(\"/gpfs/space/projects/BetterMedicine/danylo/lung/training/raw/2D_201_redbrick/images\")\n",
    "\n",
    "\n",
    "dst_dir = Path(\"predictions/test_set_201_119\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = img_dir.rglob(\"*npy\")\n",
    "val_files = [str(filepath) for filepath in val_files]\n",
    "val_files = filter_axes(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_input = {'point_prompt': 2,\n",
    "             'prob_random_pair': 0.,\n",
    "             'prob_jitter': 0.}\n",
    "\n",
    "dataset = OneclickDataset(files=val_files,\n",
    "                          ndim=ndim,\n",
    "                          mode=\"test\",\n",
    "                          add_input=add_input)\n",
    "\n",
    "val_dice = torchmetrics.Dice()\n",
    "\n",
    "for img_tensor, mask_tensor in tqdm(dataset):\n",
    "    img_tensor = img_tensor.unsqueeze(0).to(device=device)\n",
    "\n",
    "    pred = predict_frame(model=model, img_tensor=img_tensor, ndim=ndim)\n",
    "    val_dice.update(torch.tensor(pred), mask_tensor.squeeze().to(torch.int8))\n",
    "    \n",
    "    img = img_tensor.squeeze().detach().cpu().numpy()\n",
    "    gt = mask_tensor.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # # Uncomment to visualize\n",
    "\n",
    "    # img = img[0] if add_input['point_prompt'] > 0 else img\n",
    "    # img = 255 * cv2.cvtColor(0.226 * img + 0.449, cv2.COLOR_GRAY2RGB)\n",
    "    # img = img.astype(np.uint8)\n",
    "\n",
    "    # img_pred = draw_contours_from_mask(img, pred,  [255, 20, 147])\n",
    "    # img_gt   = draw_contours_from_mask(img, gt, [0, 255, 102])\n",
    "    \n",
    "    # # separators\n",
    "    # img_pred[:, 0] = 255\n",
    "    # img_gt[:, 0] = 255\n",
    "\n",
    "    # img_stacked = np.hstack([img, img_pred, img_gt])\n",
    "    # imshow(img_stacked)\n",
    "\n",
    "val_dice_mean = val_dice.compute()\n",
    "val_dice.reset()\n",
    "\n",
    "print(val_dice_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
